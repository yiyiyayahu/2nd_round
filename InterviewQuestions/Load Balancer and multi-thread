第四轮：一个白人小年轻，也是一脸笑嘻嘻的，但仍然掩饰不住问题的刁钻。让我设计 load balancer
这题比较开放，我讲了几种大概的思路，但他刁钻的提出让我从多线程的角度去分析，
如果一下来了太多的 load request 怎么办，如果你与 server 之间的沟通有延迟怎么办，怎么设置安全锁来保证你得到的当前各个 server 的状态是实时的。
我去，我记得当时我也就看了关于 load balancer 的几种处理思路，没有考虑这么多的细节，答得不是很好。
从来刷题也没刷到过考多线程这么深的问题，不知多线程问题在Google是不是很多被问到，还是我太背啊。

这个要好好准备一下啊。。。看来真正面试还真不是单纯的刷题那么简单。。。哭了


load balancer一个简单的算法就是round robin，但是有很多drawback，就是load分配不均，很可能有的server就overload，有的server没事儿干
然后呢，可以通过和server通信看这个server有多么busy来决定分配给谁

如果一下来了太多的load request呢，我的想法是用一个blocking queue先把这些request存起来，就是producer-consumer model。
queue满的时候producer不要写，queue空的时候consumer不要读，然后一个时间内只能有一个producer或者consumer access同一个object

关于server的忙碌程度呢，可以用一个thread不停的check，然后把server的state写到一个HashMap或者queue里，然后一直更新
检测server如何忙的方法呢，比如我可以知道我分配给这个server的job length，也知道当前的timestamp，可以给个estimate end time
当一个新的job进来的时候呢，就可以分配给那个estimate end time比较小的那个
这里有可能有thread contention的问题就是我在分配job的同时需要update这个存server state的queue
比如多个thread都要改这个server state queue的话就不行了，所以把这个queue做成synchronized的，一次只能一个thread改

Race Condition: 
When two processes/threads are executing concurrently, the result can depend on the precise interleaving of the two instruction streams 
(this is called a race condition)
–  race conditions cause bugs that are hard to reproduce!

•  We’d like a way to “group” these three instructions together, so that other relevant threads/processes won’t interfere with them
•  This is called the mutual exclusion problem
Need to ensure “atomic” execution of a sequence of instructions
Mutual exclusion refers to the requirement of ensuring that no two concurrent processes are in their critical section at the same time; 
it is a basic requirement in concurrency control, to prevent race conditions.


关于thread都有点忘差不多了，赶紧复习一下
https://www.javacodegeeks.com/2014/11/multithreading-concurrency-interview-questions-answers.html


For what purposes is the keyword synchronized used?
When you have to implement exclusive access to a resource, like some static value or some file reference, 
the code that works with the exclusive resource can be embraced with a synchronized block:

synchronized (SynchronizedCounter.class) {
    counter++;
}

37. What do we understand by a deadlock?
A deadlock is a situation in which two (or more) threads are each waiting on the other thread to free a resource that it has locked, 
while the thread itself has locked a resource the other thread is waiting on:
Thread 1: locks resource A, waits for resource B
Thread 2: locks resource B, waits for resource A

38. What are the requirements for a deadlock situation?
In general the following requirements for a deadlock can be identified:
Mutual exclusion: There is a resource which can be accessed only by one thread at any point in time.
Resource holding: While having locked one resource, the thread tries to acquire another lock on some other exclusive resource.
No preemption: There is no mechanism, which frees the resource if one thread holds the lock for a specific period of time.
Circular wait: During runtime a constellation occurs in which two (or more) threads are each waiting on the other thread to free a resource 
that it has locked.

39. Is it possible to prevent deadlocks at all?
In order to prevent deadlocks one (or more) of the requirements for a deadlock has to be eliminated:
Mutual exclusion: In some situation it is possible to prevent mutual exclusion by using optimistic locking.
Resource holding: A thread may release all its exclusive locks, when it does not succeed in obtaining all exclusive locks.
No preemption: Using a timeout for an exclusive lock frees the lock after a given amount of time.
Circular wait: When all exclusive locks are obtained by all threads in the same sequence, no circular wait occurs.

40. Is it possible to implement a deadlock detection?
When all exclusive locks are monitored and modelled as a directed graph, a deadlock detection system can search for 
two threads that are each waiting on the other thread to free a resource that it has locked. 
The waiting threads can then be forced by some kind of exception to release the lock the other thread is waiting on.

77. What is a semaphore?
A semaphore is a data structure that maintains a set of permits that have to be acquired by competing threads. 
Semaphores can therefore be used to control how many threads access a critical section or resource simultaneously. 
Hence the constructor of java.util.concurrent.
Semaphore takes as first parameter the number of permits the threads compete about. 
Each invocation of its acquire() methods tries to obtain one of the available permits. 
The method acquire() without any parameter blocks until the next permit gets available. 
Later on, when the thread has finished its work on the critical resource, it can release the permit by invoking the method release() 
on an instance of Semaphore.
