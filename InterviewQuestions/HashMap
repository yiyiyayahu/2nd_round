2.1怎么让一个class可以成为hashmap里的key 
A: 实现hashcode 
2.2Java里怎么实现hashcode （以前看过，一时间竟然忘了）。 
2.3 举个栗子 
2.4怎么实现hashmap （动态内存，冲突检测） 

第二道题是问答题，问了问hash function. 问如果hash function 产生confilict 该怎么办。 比如：F('A') = 123，F('B') = 123.
LZ直接说 用linkedList 解决。他又问会产生什么负面效果。LZ回答再坏情况下contains()操作需要O(n)时间。然后就过了。

hashcode:
http://stackoverflow.com/questions/113511/best-implementation-for-hashcode-method

The best implementation? That is a hard question because it depends on the usage pattern.

A for nearly all cases reasonable good implementation was proposed in Josh Bloch's Effective Java in item 8. 
The best thing is to look it up there because the author explains there why the approach is good.

A short version
Create a int result and assign a non-zero value.

For every field f tested in the equals() method, calculate a hash code c by:

If the field f is a boolean: calculate (f ? 0 : 1);
If the field f is a byte, char, short or int: calculate (int)f;
If the field f is a long: calculate (int)(f ^ (f >>> 32));
If the field f is a float: calculate Float.floatToIntBits(f);
If the field f is a double: calculate Double.doubleToLongBits(f) and handle the return value like every long value;
If the field f is an object: Use the result of the hashCode() method or 0 if f == null;
If the field f is an array: see every field as separate element and calculate the hash value in a recursive fashion and combine the values as described next.
Combine the hash value c with result:

result = 37 * result + c
Return result
@Override 
public int hashCode() {

    // Start with a non-zero constant. Prime is preferred
    int result = 17;

    // Include a hash for each field.

    // Primatives

    result = 31 * result + (booleanField ? 1 : 0);                   // 1 bit   » 32-bit

    result = 31 * result + byteField;                                // 8 bits  » 32-bit 
    result = 31 * result + charField;                                // 16 bits » 32-bit
    result = 31 * result + shortField;                               // 16 bits » 32-bit
    result = 31 * result + intField;                                 // 32 bits » 32-bit

    result = 31 * result + (int)(longField ^ (longField >>> 32));    // 64 bits » 32-bit

    result = 31 * result + Float.floatToIntBits(floatField);         // 32 bits » 32-bit

    long doubleFieldBits = Double.doubleToLongBits(doubleField);     // 64 bits (double) » 64-bit (long) » 32-bit (int)
    result = 31 * result + (int)(doubleFieldBits ^ (doubleFieldBits >>> 32));

    // Objects

    result = 31 * result + Arrays.hashCode(arrayField);              // var bits » 32-bit

    result = 31 * result + referenceField.hashCode();                // var bits » 32-bit (non-nullable)   
    result = 31 * result +                                           // var bits » 32-bit (nullable)   
        (nullableReferenceField == null
            ? 0
            : nullableReferenceField.hashCode());

    return result;

}
The signed left shift operator "<<" shifts a bit pattern to the left, and the signed right shift operator ">>" shifts a bit pattern to the right. 
The bit pattern is given by the left-hand operand, and the number of positions to shift by the right-hand operand. 
The unsigned right shift operator ">>>" shifts a zero into the leftmost position, while the leftmost position after ">>" depends on sign extension.


====================
Implement a hashmap
HashMap maintains an array of buckets. Each bucket is a linkedlist of key value pairs encapsulated as Entry objects
class Entry {
    int key;
    int value;
    Entry next;
}

Initialize - an array of buckets
put(key, value) 
- hashCode(key) - map to bucket hash & (capacity-1)
- iterate the Entry in the linked list, if replacement - update the value, if collision - append the entry to the list
- update the map bucket

get(key, value)
- hashCode(key) - map to bucket hash & (capacity-1)
- iterate the Entry in the linked list to find the corresponding value, and return


In HashMap the decision regarding which bucket a key should go to is made on the basis of this :

    static int indexFor( int hash, int capacity) {
        return hash & (capacity-1);
    }

Note that capacity is always a power of 2 (ie 1 followed by a sequence of zeroes in binary). 
So (capacity - 1) is a sequence of 1's in binary. 
So if the capacity is 2^n, then only the lower n bits of hash are useful and the upper bits beyond that are ignored
=====================
Dynamic Resizing
 
As the number of elements in the map grows, the hash chains will grow longer and retrieval time will increase. 
At some point, it makes sense to increase the number of buckets and rehash the values. 
Remember finding the correct bucket takes O(1) time while finding the correct entry in the bucket takes O(n) time. 
So it makes sense to have more number of buckets instead of having a few crowded buckets
 
HashMap always doubles up the capacity during resizing. 
It creates a new bucket array of twice the size and copies data from old array to new array. 
Then the table variable is reinitialized  with the new array

    void resize( int newCapacity) {
        Entry[] oldTable = table;
        int oldCapacity = oldTable.length ;
        if (oldCapacity == MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return;
        }
 
        Entry[] newTable = new Entry [newCapacity];
        transfer(newTable, initHashSeedAsNeeded(newCapacity));
        table = newTable;
    }

During transfer from old array to new array, it iterates over the elements of the old array, 
for every Entry element computes the new bucket array index and sets the next pointer of thst element to the head of the bucket 
(ie adds elements to the head of the singly linked list). So, the order of the linked list elements are reversed
 
Suppose original linkedlist was 1->2->3
Lets assume after resizing, every element again goes into same bucket
So, after first iteration, 1->null
after second iteration, 2->1->null
after third iteratuion, 3->2->1->null thus the link list gets reversed
 
This creates a potential race condition during resizing. 
Suppose two threads parallely decide that the HashMap needs resizing and try to resize. This may lead to an infinite loop.


======================
HashMap vs HashTable

1. Synchronization or Thread Safe :  This is the most important difference between two. 
HashMap is non synchronized and not thread safe.On the other hand, HashTable is thread safe and synchronized.
When to use HashMap ?  answer is if your application do not require any multi-threading task, 
in other words hashmap is better for non-threading applications. HashTable should be used in multithreading applications. 

2. Null keys and null values :  
Hashmap allows one null key and any number of null values, while Hashtable do not allow null keys and null values in the HashTable object.

3. Iterating the values:  Hashmap object values are iterated by using iterator.
HashTable is the only class other than vector which uses enumerator to iterate the values of HashTable object.

4.  Fail-fast iterator  : The iterator in Hashmap is fail-fast iterator while the enumerator for Hashtable is not.
According to Oracle Docs, if the Hashtable is structurally modified at any time after the iterator is created in any way 
except the iterator's own remove method , then the iterator will throw ConcurrentModification Exception.
Structural modification means adding or removing elements from the Collection object (here hashmap or hashtable). 
Thus the enumerations returned by the Hashtable keys and elements methods are not fail fast.
We have already explained the difference between iterator and enumeration.

5. Performance :  
Hashmap is much faster and uses less memory than Hashtable as former is unsynchronized. 
Unsynchronized objects are often much better in performance in compare to synchronized  object like Hashtable in single threaded environment.

6. Superclass and Legacy :  
Hashtable is a subclass of Dictionary class which is now obsolete in Jdk 1.7 ,so ,it is not used anymore. 
It is better off externally synchronizing a HashMap or using a ConcurrentMap implementation (e.g ConcurrentHashMap).
HashMap is the subclass of the AbstractMap class. 
Although Hashtable and HashMap has different superclasses but they both are implementations of the "Map"  abstract data type.
